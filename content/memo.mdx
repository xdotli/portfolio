---
title: "Benchmarkthing Memo"
publishedAt: "2024-10-20"
summary: "How we think of the product"
---


**Benchmarkthing Memo - Xiangyi Li and Moritz Wallawitsch**

**Intro**

Benchmarkthing starts off as a platform of evals and workflows, with a standardized cloud environment to execute them. It aims to become a consumer-facing stateful execution cloud for all orchestrated AI workflows. We want everyone—from developers to non-technical people—to be able to spin up a VM and execute certain tasks with just a sentence.

However, the path from A (eval platform) to B (agent cloud) might seem abrupt. A is about giving people some recipes, whereas B is about providing people with outcomes. Below, I will explain why we start from A and how we transition to B, supported by a few key insights.

**Insights**

- **AI Will Make Traditional Software Obsolete:** Software as we know it today (SaaS, tools, travel websites, etc.) will soon be past tense with AI taking over. In this AI-driven future, models become the product, and services replace software. People won't buy tools anymore; they'll hire agents to deliver results.

- **Service Is the New Software:** In the future, individuals will no longer purchase software tools to perform tasks. Instead, they will use AI agents that directly achieve their desired outcomes. These agents will replace traditional tools by offering services as outcomes—like hiring an expert to solve a problem rather than buying the tools needed to solve it.

- **Generic LLMs Won't Suffice:** Current large language models are like off-the-shelf products—limited in flexibility and applicability. In contrast, domain-specific and customizable models will be key. Agents will be tailored to user needs—more akin to chef-cooked meals rather than frozen dinners.

- **Every User Will Own Personalized Agents:** The landscape of agents won't consist of one standard solution per domain. Instead, there will be billions of personalized agents, each tailored to its owner’s specific requirements. This long-tail effect means our agent orchestration cloud will cater to diverse, niche requirements—like personalized software used uniquely by each user.

But before we get there, we need AI evals to establish a foothold for both LLM systems and AI infrastructure.

**Product Strategy**

**Step 1: AI Eval and Workflow Platform + Execution Runtime**  
We begin with an eval platform and execution runtime for two reasons:

1. **Immediate Demand:** The need for evaluation tools is urgent and growing rapidly as AI adoption increases.
2. **Foundational Value:** This establishes a strong foundation for the next steps, enabling us to gain traction and credibility in the market. By becoming the go-to for AI evals, we lay the groundwork for workflow standardization.

For example, we've seen companies like Trellis successfully use our current platform for PDF-to-SQL pipeline evals, which saved them considerable time and effort. The demand for these capabilities is clear, and we are uniquely positioned to deliver them.

**Step 2: Orchestration Cloud with a Master AI Node**  
In Step 1, we build cloud-native workflows and evaluation processes. We then take it a step further by adding a master AI node capable of taking user input, identifying the appropriate workflow, and customizing it. For instance, a user might type `bench run 'optimize marketing campaign'`. The AI node will spin up a VM, find relevant workflows, iterate on them, and return a ready-to-use solution, available with a simple call like `bench.run('workflow-123')`.

This step introduces the orchestration capabilities that underpin our agent cloud vision. The master AI node’s ability to integrate workflows and evaluate them autonomously provides the backbone for moving from evals to functional AI orchestration.

**Step 3: Reliable Agent for Everyone**  
Finally, we make the transition to a consumer-facing agent cloud. By this stage, our cloud-native workflows will be thoroughly tested and reliable, achieving a 98% success rate. This will enable us to serve non-technical users with personalized agents that can perform complex tasks—for example, planning a multi-city trip to Japan by referencing favorite travel blogs, past conversations, and optimizing flights and hotels.

In this future, agents become collaborators, communicating and integrating across domains in ways traditional software never could. Imagine an agent cloud where agents work together much like colleagues on Slack—sharing information, running evaluations, and delivering complex solutions seamlessly. This inter-agent communication is key to our differentiation.

**Why This Approach?**

Starting with evals allows us to build a critical foothold in the AI ecosystem. We establish reliability and trust, both with developers who require sophisticated evaluations and with the broader AI community. From there, we build up the orchestration capabilities that pave the way for a personalized agent cloud—not as an abrupt leap, but as an organic growth built on a solid foundation.

In short, Benchmarkthing evolves from an essential developer tool to a universally accessible agent cloud, empowering users across all levels of technical ability.

